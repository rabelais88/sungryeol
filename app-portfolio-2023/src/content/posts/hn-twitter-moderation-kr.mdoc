---
title: '번역: Reddit CEO 출신이 바라보는 트위터 검열'
tags:
  - tech
publishedAt: 2022-11-16T15:00
---

* [트위터 원문](https://twitter.com/yishan/status/1586955288061452289 "")
* [by threadreader app 으로 본문 한 번에 읽기](https://threadreaderapp.com/thread/1586955288061452289.html "")

> 역자 한마디: "트위터의 컨텐츠 수위 이슈를 어떻게 해결할 수 있을 거라고 보나요?" 라는 질문에 트위터에서 레딧의 전 운영자인 [Yishan](https://twitter.com/yishan "")이 답한 내용을 번역해 보았습니다. 초대형 사이트의 컨텐츠 검열이라는 내용 자체가 매우 독특하고도 흥미롭습니다. 커뮤니티의 운영자가 되려 하거나 대형 커뮤니티 구성에 관심이 있는 사용자라면 한 번쯤 읽어보면 좋을 글 같습니다.

사람들이 제일 많이 오해하는 부분 인데요, 검열 관리는 컨텐츠 중심으로 볼 것이 아니라 신호-대-잡음(signal to noise)문제로 보아야 합니다.

정치적 극단화가 너무 심해지다보니 발화의 내용이나 증오 발언, 페이크 뉴스, 검열 등의 이슈로 쉽게 관심이 쏠려버립니다.

이 미궁 속에 빠져버리면 결국 "현자들의 의회(council of wise elders)"같은 걸 만들게 됩니다. 마치 솔로몬 마냥 소수의 인원이 어떤 컨텐츠를 허용하고 금지할지를 명확하게 지정해주는 집단 말이지요. 물론 실제로는 그렇게 될 수도 없습니다. 이 현자들은 무더기로 살해 협박을 받고, 결국 일을 그만 두게 될겁니다...

그만 둔 사람들의 자리를 메우기 위해 다음 사람을 고용하면 그 사람들은 먼저 그만둔 사람에게 왜 그만두었는지를 물어보고 구인 요청을 거절할겁니다. 결국에는 "정치적인 동기가 있는 미치광이와 덜떨어진 얼간이들로 구성된 의회(a council of third-rate minds and politically-motivated hacks)"를 구성할 수밖에 없는 것이죠. 상황은 훨씬 악화될 겁니다.

의회 참여자들의 익명성을 보장한다고 해결할 수 있는 문제도 아닙니다. 그러면 결국 신뢰할 수 없는 "비밀 엘리트들의 특수 결사(Star Chamber of secret elites)"를 운용하고 있다고 오해받을 겁니다. 그렇게 되어서는 안돼죠. 공적이고 **신뢰할 수 있어야** 합니다!

그러니까 문제는 (컨텐츠 수위 관리에서) **무엇**을 말하느냐에 관심이 쏠린다는 것입니다. 현실은 왜 그렇지 않은지 알려드리도록 하죠.

이 논의에서 요긴하게 사용할 수 있는 관점이 있습니다: 여러분이 어떤 소셜 네트워크의 컨텐츠 수위 관리를 직접 한다고 상상해보세요. **그런데 여러분은 그 소셜 네트워크의 언어를 이해하지 못하는 것입니다.**

언어를 마치 외계어처럼 받아들이면 컨텐츠에 관련된 메타 데이터(meta-data)를 관측할 수 있을 것입니다. 예를 들자면 빈도수나 글이 올라오는 패턴 따위요.

여기서 어떻게 하면 소셜 네트워크를 "좋게"만들고 사용자에게 긍정적인 잇점을 전달할 수 있을까요?

일단 컨텐츠 수위 관리에 있어서 사용되는 관리 단계를 보여드리자면 이렇습니다:

1. 스팸
2. 이슈가 되지 않는 주제거리
3. 이슈가 되는 주제거리(정치, 종교, 문화 등...)

소셜 네트워크를 만들고 나면 반드시 **우선적으로** 관리할 필요성이 생기는 것은 1. 스팸입니다. 재앙, 화재급에 가까운 논쟁들 조차도 작은 소셜 네트워크에는 보통 장점일 수 있습니다: 사용자들의 참여를 증진시키기 때문입니다. 오프라인으로 실제로 피해를 입히는 것도 아닙니다. 그렇게 되면 컨텐츠 수위 관리를 할 필요성이 생기겠지만 말이예요. (당연히 플랫폼 운영자들은 컨텐츠 수위 관리를 하고 싶지 않아합니다. 그들에게는 추가적인 일거리일 뿐더러 집중하고 싶은 다른 것들이 있거든요.)

스팸 관리는 매우 흥미롭습니다. 거의 모든 사람들이 스팸을 금지시키거나 검열할 수 있어야 한다고 생각하지만, 스팸이 법적으로 불법일리가 전혀 없습니다.

스팸은 "모든 합법적인 발언을 허용할 것"이라는 기준에 놓고 보면 100% 아무런 문제도 없습니다. 까놓고 말하자면, 미국 우체국 조차도 우편함에 광고성 스팸 메일을 배달하거든요.

개인 플랫폼의 자유 발언은 (미국 헌법의) 발언 자유 보장 법을 따라 만들어져 있습니다. 이 플랫폼들의 발언 자유에 대해 논할때면, 흔히 예외로 언급되는 것들이 "자리가 만석인 극장에서 총을 쏜다"거나, "직접적인으로 위해를 가하겠다"하는 것들입니다. 스팸은 그런 것들과는 전혀 거리가 멉니다. 하지만 사람들은 여전히 말하죠: 네, 스팸은 검열하고 차단할 수 있어야 합니다.

왜 그럴까요? 가치가 없기 때문인가요? 가끔은 거짓말이 섞여 있어서 그런가요? 오프라인에서 실제로 피해를 미치는 것이 전혀 아닌데도요? 정답은 모두 X입니다.

다들 발언의 자유가 보장되어야 한다는 것에는 동의합니다.(예를 들자면 똥글 shitposting도 흔하잖아요) 그러나 컨텐츠가 사실이 아니기 때문에 검열해야 된다는 명제에 대해서는 명확하지 않은 부분이 있습니다.(어떤 것이 진실인지 조차도 명확하지 않을 때가 있으니까요) 결론은 뭘까요? 왜 스팸을 차단할까요?

대답은 모두가 잘 알고 있습니다: 스팸을 차단하는 것에 대해서는 명확한 이치가 없습니다. 순전히 결과론적인 이유에서 스팸을 차단할 뿐입니다. 스팸은 사용자 경험의 질에 영향을 주고, 사용자들이 플랫폼에서 좋은 시간을 보낼수록 플랫폼은 성공하기 때문입니다. (물론 소셜 플랫폼에서 성공적이라는 것은 수익이 짭짤한 광고 프로그램이 있다는 뜻입니다. 이는 아이러니하게도 스팸을 증가시키지만 말이죠.)

뿐만 아니라, 언어를 이해하지 않고도 대개는 스팸을 분별하고 차단할 수 있습니다.

스팸은 반복적인 특성과, 컨텐츠의 단순성 때문에 패턴 추적이 어렵지 않고 아주 쉽게 분별됩니다. 머신 러닝은 정확하게 스팸을 분별해낼 수 있지만, 머신러닝이 스팸의 본문에 있는 비아그라나 모기지론 재투자에 대해서 잘 이해하고 있기 때문이 아닙니다. 스팸은 독특한 글쓰기 패턴이 있기 때문입니다.

게다가 AI는 처음 보는 스팸조차도 판별해낼 수 있습니다.

새로운 컨텐츠(예를 들면 정치 이슈)를 검열하는 것과는 다릅니다. 관리자들은 "새로운 이슈"가 나중에 문제가 되어서 관리가 필요해질지 아닐지를 보통 미리 알아내지 못합니다.

하지만 상당히 새로우면서도 퀄리티 자체는 낮은 사기 제품 같은 것은 AI가 패턴을 통해 쉽게 판별해낼 수 있습니다. AI는 그 내용을 전혀 이해하지 못하지만 말이예요.

AI는 그저 어떤 메시지가 사용자가 원치 않는 "특정 행동 패턴"을 가지고 송신되었다는 것을 알 뿐입니다. 키워드 기반이 됐든, 글쓰기 주기가 됐든, 혹은 콘텐츠와 무관한 패턴 매칭이든, 스팸 필터는 그저 소셜 미디어 플랫폼의 소유자들이 콘텐츠의 신호-대-잡음(signal -to-noise) 비율을 개선하기 위해 사용하는 도구일 뿐입니다.

이것이 스팸 검열의 정체입니다. 앞서 말했듯, 주제가 검열되는 것이 아닙니다. 그 행동 패턴이 검열될 뿐입니다.

이제 관리 단계의 다음 내용으로 넘어가 봅시다:

1. 이슈가 되지 않는 주제거리
2. 이슈가 되는 주제거리(정치, 종교, 문화 등...)

이슈가 되지 않을만한 주제거리를 가지고 토론에 참여하고 있다고 해 봅시다. 보통은 별 문제 없이 진행될 겁니다. 하지만 가끔은 예외적으로 병적인 상황이 발생합니다.

A. 특정 사용자가 주제에 지나치게 몰입되어 계속해서 같은 내용을 올리기 시작하거나, 누군가가 아주 조금이라도 관계된 내용을 올리면 발작해서 자기의 의견을 개진하기 시작하는 것입니다. 이 사용자는 절대 입을 다물지 않습니다. 어투는 짜증을 유발하는 수준에서 누가 들어도 화가 날만한 수준에 도달할 수도 있습니다.

B. 아주 무해한 주제가 재난급 말싸움을 일으키는 것도 있습니다. 예를 들어 누군가가 존 멀레이니(역주: 존 멀레이니는 비교적 가벼운 농담을 위주로 하는 이미지가 좋은 스탠드업 코미디언입니다)의 농담에 대해 이야기를 꺼냈는데 이것으로 인해서 "존 멀레이니를 좋아해도 되는가"에 대한 논쟁이 시작되는 것입니다. "존 멀레이니는 어쩌다 그렇게 좋지 않은 말을 했담...그 사람이 그런 말을 하는걸 어떻게 그냥 놔둘수가 있나요..." 같은 논쟁이죠.

**제가 말로 묘사하는 방식**은 그다지 듣기 나쁘지 않습니다. 하지만 여러분이 소셜 플랫폼을 사용하시면서 경험한 가장 극단적이고 병적인 예시를 상상하기를 바랄께요: 그 사람은 자신의 의견과 관련이 있는 모든 주제의 게시판(쓰레드)에, 물론 주제가 연관이 아주 없지는 않겠습니다만, 계속 똑같은 내용을 주구장창 언급합니다. 그러면 거기에 있는 사소한 댓글로 인해 재난적인 논쟁이 시작되는 겁니다. 계속 끝을 물고 늘어지는 것은 물론이거니와 서로가 서로를 싫어하게 되고, 척을 진 사람들의 부대가 형성되며 플랫폼의 일부 아주 훌륭한 사용자들은 **역겨워서** 플랫폼을 탈퇴하고 맙니다.

여러분들이 좋아하시던 그 커뮤니티에서 그런 일들이 일어났던 것을 기억하시나요? 그냥 생각하기만 해도 혈압이 오르시지 않나요?

하지만 스팸과 마찬가지입니다. 이러한 주제들은 (표현의 자유에 따라)절대 불법적인 내용이 아닙니다. 하지만 모두가 그렇듯이 세상은 결론에 따라 움직입니다. 그러한 작용들은 사용자들이 플랫폼에 반감을 갖게 하고 더 많은 사용자가 떠나게 만듭니다. 플랫폼의 소유주라면 마법같이 이런 일들이 해결돼서 아예 일어나지 않기를 바랄 겁니다.

대부분의 (플랫폼)사용자는 저명한 과학자나 똑똑한 철학자(역주: 여기서는 Eliezer Yudkowsky와 Scott Alexander라는 인물을 인용하고 있습니다)가 **아닙니다**. 논쟁적인 글을 보면서 "흠, 내가 무언가 잘못한 것이 있었나?"라고 생각할 겨를이 없습니다. 대부분의 사람들은 그저 쉽게 동요할 뿐입니다.

이러한 일들은 예측할 수도 없을 뿐더러 무조건 일어나게 되어 있습니다. 그러니 플랫폼 소유주가 할 수 있는 것이라곤 아무것도 하지 않거나(운에 따라 성공하든 실패하든 내버려 두는 것입니다) 그냥 어느정도는 적당히 관리검열 하는 것입니다.

**바로 이 부분에서** 여러분들의 머리에 떠오르는 잘못된 생각을 하나 정정했으면 합니다.

적당히 관리검열 한다는 것은 **절대로** 누군가 한 명이 고안한 방법을 따라간다는 뜻이 아닙니다. 그것이 최선이든 옳은 것이든, 심지어는 아주 좋은 것이라고 해도요.

저는 이 부분에서 **절대로** 검열, x일 접속 제한, 완전 접속 제한, 키워드 검열, 어떤 방식이 되었든 검열을 옹호하는 것이 아닙니다. 결국 문제는 포스팅을 하는 행동의 문제이지 내용의 문제가 아니란 말입니다. 제 말의 뜻이 뭐냐구요?

그 말의 뜻인 즉슨, 그렇게 할 경우 사람들은 여러분에게 "존 멀레이니의 이혼이 옳은 것인지 아닌지를 논하지 못하도록 검열했지만 칸예 웨스트가 반 유대인적인 발언을 한 것이 옳은 것인지를 논하는 것에 대해서는 그냥 놔두었어요! 이 플랫폼 소유주는 인종차별자입니다!"라고 하게 될 겁니다. 물론 사실이 아닙니다. 어쩌다보니 사람들은 그저 칸예 웨스트에 대해서는 심각한 키배를 벌이지 않았을 뿐인 것이고, 그저 운좋게 칸예 웨스트라는 주제에 대해 매몰되어 계속 똑같은 글을 올리는 사내가 이번엔 없었을 뿐인 것입니다.

이제 다시 한 번 질문드려 보겠습니다: 본문이 알아들을 수 없는 언어로 되어 있어서 내용을 전혀 이해하지 못하더라도 컨텐츠를 검열할지 하지 않을지에 대한 결정을 내릴 수 있을까요?

디자인에서도 "로렘 입숨"을 비슷한 용도로 사용합니다. (역주: 로렘 입숨은 디자인용 샘플 텍스트입니다. 내용은 중요하지 않고, 글의 배열만 사용되는 점을 비유합니다)

클라이언트에게 디자인 시안을 제시할 때, 전문가 디자이너들은 텍스트를 엉뚱한 텍스트로 대체하곤 합니다. 예를 들면 "나랏말싸미 듕귁에 달아..."같은 글을 사용합니다. 왜냐면 프로 디자이너들은 글의 내용이 클라이언트에게 무의식적으로 영향을 주는 것을 피하려고 하기 때문입니다.

예를 들자면 본문의 내용이 "스틸러스는 역사상 가장 훌륭한 미식축구 팀이다"라면, 어떤 클라이언트들은 무의식적으로 그 디자인을 훨씬 좋아하게 될 수도 있지만, 반대로 싫어하게 될 수도 있습니다.

(라이벌인 피츠버그를 응원하는 독자분이라면 이 내용의 진실성에 의문을 품게 되면서 저의 주제에 대해 다시 한 번 고찰하는 기회가 될 겁니다)

사람들이 플랫폼의 검열 결정에 대해 판단할 때, 컨텐츠의 주제는 그냥 무의식적으로 영향을 주는 수준이 아닙니다. 컨텐츠의 주제에 따라 사람들이 검열 결정을 판단하는 방식은 무차별적으로 바뀌게 됩니다!

지금 검열 방식에 문제가 있다고 생각하는 커뮤니티에 대해, 연루된 집단들의 정치적 정체성이 완전히 반대라고 상상해 본다면 이제 좀 너그러워지실 수 있으려나요?

본문의 내용을 완전히 이해하지 못할 때에야 비로소 관리 검열 정책의 효과를 조금 더 확실하게 이해할 수 있을 것 같지 않나요?

중국 사람들은 미국의 정치적인 정당들이 서로 다르다고 생각하지 않습니다. 그저 성난 군중이 선거 이후에 수도를 점령한 결과로 태어난 혼란스럽고 무질서한 시스템이라고 생각할 뿐입니다. 만약 나쁜 짓을 벌인다 해도 마찬가지입니다. 러시아는 미국에서 질서정연한 권력의 승계가 일어나지 않고 이러한 문화가 생긴 것에 기뻐하고 있을 겁니다. 누가 "착한 편"인가는 중요하지 않습니다. 그냥 우리의 소셜 플랫폼을 좋아할 따름이죠.

말을 하다 보니 2번 주제에서 3번 주제로 은근슬쩍 넘어가 버렸네요.

1. 이슈가 되지 않는 주제거리
2. 이슈가 되는 주제거리(정치, 종교, 문화 등...)

왜냐면 2번 주제는 3번 주제로 자연스럽게 연결되어 버리거든요. 3번 주제의 어떤 것과 문화적 연관이 있더래나 뭐래나 - 그러고 나면 결국 3번 주제를 논하게 되거나 3번과 관계된 이야기를 하게 되죠.

2번의 이슈가 되지 않는 주제거리란 백신과 마스크와 같은 것입니다.

10년 전으로 돌아가서 여러분이 저에게 사람들이 마스크를 쓰는 것에 때문에 글로 토론을 벌이고 심도있는 문화 정체성 분열을 일으킨다고 알려줘 보세요. 저는 여러분이 미쳤다고 할 거예요.

이런 것들은 예측할 수 없습니다. 그러니 귀납적으로 일어나지 않은 일에 대해 미리 규칙을 만들어 둔다는 것은 불가능해요. **반드시** 주제를 냉정하게 정치와 분리된 방식으로 바라 보아야만 합니다.

언제쯤 새로운 주제가 플랫폼의 유지에 위협적인 문제를 촉발시킬지 예측하는 것은 사람에게나 AI에게나 어렵습니다. 충분히 문제가 될만한 사용자 행동들을 관측하는 것 말고는 다른 방법이 없습니다.

하지만 이러한 내부 사정은 외부에 보이지 않습니다. 플랫폼은 문제 있는 사용자들의 행동을 굳이 밖에 드러내놓고 다니지 않거든요. 그런걸 사용자들이 알게 되면 사용을 꺼릴 것을 알기 떄문입니다.

사용자들이 볼 수 있는 것은 오로지 **트위터/페이스북**이 **유명한 유저**가 **문제되는 이슈에 대해**글을 올렸다는 이유로 검열했다는 내용의 (주류 뉴스 속) 자극적인 헤드라인 뿐입니다.

구식 매체 언론인들이 컨텐츠에 대해 늘상 그러한 관심만을 가지고 있기 때문에 이런 일이 일어나는 것입니다. 신문 언론들은 "멈추지 않는 똥글 생산 유저들"이나 "집단간의 과다한 논쟁(어떤 집단일지...아마도 싸움 중인 편집자들이라고나 해야할까요?)"과 비슷한 것을 겪어 본 적이 없습니다. **컨텐츠**가 어떤 것인지는 구조적으로 아예 이해 범위 바깥입니다.

소셜 미디어 이전의 컨텐츠란 "사람들이 관심을 가질만한 것, 이상적으로는 심리적으로 동요하게 만들 수 있으면 더 좋은 것" 이었습니다. 도대체 무슨 이유로 그런 것을 검열하겠습니까? 아주 얼토당토 않은 이유 말고는 없습니다.

구식 매체 언론사들은 논쟁을 일으킬 수 있는 내용을 출판할 수 있다면, 어떤 것이든 **좋아라**할 것입니다. 구식 매체를 통하여 발생될 수 있는 논란거리란 오늘날 소셜 미디어의 관점에서 보면 거의 **반작용이 없는 것**이나 마찬가지입니다.

학보사에 다닐적에 학교 신문에 황당한 내용의 풍자 컬럼을 주간으로 기고했습니다. 풍자는 간혹 당사자가 이해하지 못하는 내용들이었습니다. 덕분에 편집자는 다른 컬럼 기고자와 일할떄보다 더 많은 투서를 받았습니다. 신문사는 저를 아주 좋아라 했지요.

(아니면 그저 제가 데드라인을 어기지 않고 매주 제 때에 기사를 송고했기 때문에 좋아했을 수도 있기는 합니다)

어찌됐든, 구식 매체에서 발생하는 논란은 구식 매체 뉴스 언론의 소비에 나쁜 영향을 주기에는 한참이나 모자랍니다. **어쩌면** 어떤 광고주는 불만을 표시할 수도 있지만, 장막 뒤의 세일즈 팀 내부 회의에서는 모든 사건이 정리되면 논란의 주인공들을 다시 기용하고자 할 겁니다.

다음과 같은 사건이 일어나는 것을 관찰할 수 있습니다:

1. 무해한 논쟁이 발생
2. 무언가 문제가 될만한 일이 발생하여 사용자들이 간섭을 일으킬 수준의 빈도와 분량으로 글을 올리기 시작함
   a. 글쓰기의 강도가 증가한 영향으로 특정 유저는 오프라인에서 무언가를 할 수도 있음.
   ... 
3. 플랫폼 소유주가 논쟁의 정도를 줄이기 위해 개입하여 검열함.
4. 논란이 발생하고 있는 컨텐츠에 대해 검열하고 있다는 골자로 언론이 기사를 올림
5. 플랫폼은 "아니오, 사용자가 좋지 않은 특정 행동을 했습니다" 혹은 "특정 규칙을 위반했습니다"라고 공지함
   ... 
6. 아무도 믿지 않음
7. 언론은 가장 화제가 될 수 있는 각을 잡고 기사를 기고함. "**A 플랫폼**은 **B 주제**에 대해 편향된 모습을 보여주고 있는가?"

왜냐면 논쟁거리가 될만한 이슈는 표현의 자유 이슈로 보이기 때문입니다.

스팸이거나 논쟁거리가 되지 않을 이슈에 대해서는 아무도 표현의 자유를 들먹이지 않습니다. 존 멀레이니에 대한 쓰레드를 차단했다 하더라도, 실뜨개 동호회 페이지의 화목함에 방해가 되어서 그랬다고 하면 모두들 이해할 수 있을 것입니다.

> "OO씨, 당신은 XX씨에 대한 말싸움을 멈추지 않고 XX씨가 게시판에서 당신을 차단하자 심지어 이메일로도 아주 나쁜 메시지를 보냈기 때문에 차단되었습니다."

논쟁적인 주제는 참여자들이 과열되면 간혹 내용이 과장됩니다. 감정적으로 동요한 참여자들은 평소같으면 하지 않았던 행동들도 참여하게 돼죠.

하지만 플랫폼을 운영하지 않는 사람들에게는 이러한 차이가 보이지 않습니다.

플랫폼의 약점이 될 수 있는 부분 중 한 가지는, 현실 세계의 사법 절차와 달리 플랫폼이 모든 사정과 내용을 외부에 공개하고 심사받을 수 없다는 것입니다.

현실 세계의 재판 과정은 보통 외부에 공개됩니다. 추정되는 범죄의 증거가 제시되고 공적으로 기록됩니다.

귀찮아서 굳이 찾아보지 않는 사람도 있을 것 같지만, 사건에 관심이 있는 분석가라면 사건의 증거를 미리 찾아보고, 원하기만 한다면 시스템에 반기를 들고 일어날 성난 군중을 모아볼 수도 있을 겁니다.

레딧에서는 사용자의 검열(예를 들면 차단)에 대해 결정을 내려야 하지만 사용자들의 위반 사실을 외부에 모두 공개할 수 없습니다. 내용을 위반하는 메시지나 협박, 다중 계정으로 올린 도배글 같은 거요.

이유는 개인 메시지는 개인만 볼 수 있기 때문이다 라거나, 관련되지 않은 집단에 내용 누설이 될 수 있어서기도 하고 여러가지가 있지만, 이쪽의 이유야 어찌 되었건 사악한 사용자들이 자신은 오히려 피해자라고 주장할 때 요긴하게 이용될 수 있기 때문이죠.

... 그리고 정치적으로 관심이 있는 집단은 플랫폼이 자신들에게 불리하게 편향되어 있다는 메시지를 더욱 증폭시킬 수 있게 됩니다.

"쫄리면 뒈지시던가" 방식에 대해서도 오랫동안 생각해 봤습니다. 검열을 받아들이지 못하는 사용자들이 자신의 **모든** 행동과 개인 메시지를 플랫폼에 공개할 수 있도록 동의하는 방식 말이죠.

그러나 사생활 침해 문제가 있을 뿐더러, 전체 공개 시스템을 구성하는 것도 상당한 일입니다. 대중이 쉽게 이해할 수 있는 방식으로 검열 방식과 그 과정을 재구성하는 일도 오랜 작업이 필요할 것입니다.

소셜 플랫폼은 이른바 **현실 세계**보다 사용자의 위반 행위에 대해 훨씬 상세하고 디테일한 자료를 가지고 있습니다. 현실 세계에서 사실이란 감춰지거나 모호해질 수 있습니다. 디지털 플랫폼에서는 모든 행동이 기록됩니다. 사실은 거기에 있습니다.

뿐만 아니라, 모든 증거는 확실한 평가를 위해 익명으로 제시될 수 있습니다.

앞서 말씀 드렸던 "우리가 이해하지 못하는 언어"처럼 만들어 볼 수 있을 겁니다. 개인을 식별할 수 있는 내용과 정치적인 이름표를 제거하는 방식으로요: 관리자들은 행동을 지켜보고 접근 금지를 결정할 수 있습니다.

물론 많은 작업이 필요할 겁니다. 그냥 자료를 모두 풀어버릴 수는 없습니다. 감정적인 긴장이 한껏 극도에 달해있는 상황이니까요: 처음 이런 일을 하게 되면 자료 일부가 사고로 새어나갈 수 있습니다. 그렇게 되면 처리할 일이 하나 더 늘어나는 거죠. 이제 문제가 두 개가 되어버리는 겁니다.

그러니 (쫄리면 뒈지시던가 방식이) 가능한 방식인지 잘 모르겠습니다. 하지만 모두가 컨텐츠 검열 관리 방식에 대해 다르게 생각해 봐야한다는 것은 분명합니다. 왜냐하면:

1. 이것은 신호-대-잡음 관리 이슈입니다
2. 표현의 자유를 어떻게 할 것인가와는 아무런 관련이 없습니다(스팸 메시지를 참고하세요)
3. 언어를 이해하지 못하더라도 관리할 수 있나요?

주의: 절대 3번을 곡해해서 모든 검열작업을 AI에게 맡기는 일은 하지 마세요. 페이스북이 이를 시도해 봤다가, 비 인간적이고 기괴한 지옥을 만든 적이 있습니다. (이와 관련해서 궁금한 사람들이 있다면 이야기를 더 풀어볼 수도 있어요.)

그럼에도 불구하고, 엘론 머스크가 트위터에 고용했다는 소문이 있는 "작전 팀"에 대해 한 마디를 덧붙이고 싶네요:

> rat king @Mikelsaac
> (트위터 쓰레드) 내가 이해한 바에 따르면 트위터 본부에는 "작전 회의실"이라는 것이 있어서 그곳에서 모든 전략을 계획한다고 해. 그 곳에는 일론 머스크, David Sacks, Jason Calacanis (일론의 패거리이면서 VC 투자자) Sriram Krishnan (전 트위터/현재 a16z), 일론의 법무와 금융팀 수장들 (Spiro, Birchall) 그리고 테슬라와 보링컴퍼니 엔지니어들이 있다고 하더군.

저의 경우 다른 사람은 잘 모르겠습니다만, (그래도 Sriram은 대단한 분이긴 합니다. 저의 작은 벤처에 잠깐 투자자로 있었어요), 적어도 [@DavidSacks](https://twitter.com/DavidSacks "")가 포함되었다는 점에 고무되네요.

Sacks는 정말 훌륭한 운영자입니다. 특히 오늘날의 테크 시대 최고의 운영자 중 하나라고 할 수 있죠. Zenefis(역주: 2022년 11월 기준 4천 3백만 달러급, 직원 500명의 거대 HR 회사)가 큰 위험에 빠졌을 때 회사의 도움 요청에 응하여 회사를 살려낸 장본인입니다.

"컨텐츠 검열"은 트위터에서 가장 눈에 띄는 문제점일 겁니다. (특히 참견하기 좋아하는 사람들이 아주 과몰입하기 좋아하는 대상입니다) 하지만 트위터가 여러가지 운영상 문제에 시달리고 있다는 점은 잘 알려져 있습니다. 많은 CEO들이 어떻게든 손을 서보려 했지만 속수무책이었죠.

트위터가 정말로 잘 운영되었다면 (앞에서 언급한) 태생적으로 매우 어려울 수 밖에 없는 무문제들을 잘 해결했을 가능성이 있습니다. 모두에게 도움이 될만한 좋은 신선한 해결책을 고안해 냈겠지요. 만약 그것이 가능한 사람이 있다면, 그게 바로 David Sacks일 겁니다.

인생 최고의 업적을 이루어서 나중에 회고를 할 여유가 있을 정도가 되지 않는 한, 트위터 직원들은 해고당하기 직전입니다.

(역주: [Block Party App](https://www.blockpartyapp.com/ "")에 대한 광고가 있으나, 이 부분은 생략했습니다.)

이 글을 재미있게 즐기셨고, 소셜 미디어에 관해 더 화끈한 분석을 원하신다면 저를 팔로우 해 주세요!
